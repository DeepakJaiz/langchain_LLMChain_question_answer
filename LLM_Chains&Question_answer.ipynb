{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8c4254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'your api key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc081d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': 'colorful socks', 'text': '\\n\\nSocktastic!'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "\n",
    "prompt_template = \"What is a good name for a company that makes {product}?\"\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate.from_template(prompt_template)\n",
    ")\n",
    "llm_chain(\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b76391da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nSocktastic!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.run(\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f476dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = [\n",
    "    {\"product\": \"socks\"},\n",
    "    {\"product\": \"computer\"},\n",
    "    {\"product\": \"shoes\"}\n",
    "]\n",
    "\n",
    "text_output = llm_chain.apply(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc45a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(text_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6eedd8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': '\\n\\nCozy Toes Socks.'}, {'text': '\\n\\nTechCore Solutions.'}, {'text': '\\n\\nFootwear Factory.'}]\n"
     ]
    }
   ],
   "source": [
    "print(text_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b821073e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '\\n\\nTechCore Solutions.'}\n"
     ]
    }
   ],
   "source": [
    "print(text_output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89183489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='\\n\\nSocktastic!', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nTechCore Solutions.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nFootwear Factory.', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'prompt_tokens': 36, 'total_tokens': 55, 'completion_tokens': 19}, 'model_name': 'text-davinci-003'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.generate(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc99a44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nSocktastic!'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(product=\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "433ec42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nQ: What did the duck say when his friend died?\\nA: Quack, quack, goodbye.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Tell me a {adjective} joke about {subject}.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"adjective\", \"subject\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=OpenAI(temperature=0))\n",
    "\n",
    "llm_chain.predict(adjective=\"sad\", subject=\"ducks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35b2d1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Red, orange, yellow, green, blue, indigo, violet\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "template = \"\"\"List all the colors in a rainbow\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[], output_parser=output_parser)\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "text_output1 = llm_chain.predict()\n",
    "print(text_output1)\n",
    "print(type(text_output1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ef357e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Red', 'orange', 'yellow', 'green', 'blue', 'indigo', 'violet']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "text_output2 = llm_chain.predict_and_parse()\n",
    "print(text_output2)\n",
    "print(type(text_output2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c26b7de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nQ: What did the duck say when his friend died?\\nA: Quack, quack, goodbye.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Tell me a {adjective} joke about {subject}.\"\"\"\n",
    "llm_chain = LLMChain.from_string(llm=llm, template=template)\n",
    "llm_chain.predict(adjective=\"sad\", subject=\"ducks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74d8acf",
   "metadata": {},
   "source": [
    "### Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2f5bcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Using cached chromadb-0.3.26-py3-none-any.whl (123 kB)\n",
      "Collecting duckdb>=0.7.1\n",
      "  Downloading duckdb-0.8.1-cp310-cp310-win_amd64.whl (9.8 MB)\n",
      "     ---------------------------------------- 9.8/9.8 MB 3.3 MB/s eta 0:00:00\n",
      "Collecting clickhouse-connect>=0.5.7\n",
      "  Downloading clickhouse_connect-0.6.2-cp310-cp310-win_amd64.whl (225 kB)\n",
      "     -------------------------------------- 225.7/225.7 kB 4.6 MB/s eta 0:00:00\n",
      "Collecting posthog>=2.4.0\n",
      "  Using cached posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
      "Collecting tokenizers>=0.13.2\n",
      "  Using cached tokenizers-0.13.3-cp310-cp310-win_amd64.whl (3.5 MB)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from chromadb) (4.65.0)\n",
      "Requirement already satisfied: pandas>=1.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from chromadb) (2.0.1)\n",
      "Collecting uvicorn[standard]>=0.18.3\n",
      "  Using cached uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from chromadb) (1.23.5)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from chromadb) (1.10.7)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from chromadb) (4.5.0)\n",
      "Collecting hnswlib>=0.7\n",
      "  Using cached hnswlib-0.7.0.tar.gz (33 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting fastapi>=0.85.1\n",
      "  Downloading fastapi-0.97.0-py3-none-any.whl (56 kB)\n",
      "     ---------------------------------------- 57.0/57.0 kB ? eta 0:00:00\n",
      "Collecting pulsar-client>=3.1.0\n",
      "  Using cached pulsar_client-3.2.0-cp310-cp310-win_amd64.whl (3.4 MB)\n",
      "Collecting onnxruntime>=1.14.1\n",
      "  Using cached onnxruntime-1.15.0-cp310-cp310-win_amd64.whl (6.7 MB)\n",
      "Collecting overrides>=7.3.1\n",
      "  Using cached overrides-7.3.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from chromadb) (2.30.0)\n",
      "Requirement already satisfied: zstandard in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (0.19.0)\n",
      "Requirement already satisfied: urllib3>=1.26 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.15)\n",
      "Requirement already satisfied: lz4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (3.1.3)\n",
      "Requirement already satisfied: pytz in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.5.7)\n",
      "Collecting starlette<0.28.0,>=0.27.0\n",
      "  Using cached starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.9)\n",
      "Collecting coloredlogs\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.23.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=1.3->chromadb) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.28->chromadb) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm>=4.65.0->chromadb) (0.4.6)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.0.4)\n",
      "Collecting websockets>=10.4\n",
      "  Using cached websockets-11.0.3-cp310-cp310-win_amd64.whl (124 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Collecting watchfiles>=0.13\n",
      "  Using cached watchfiles-0.19.0-cp37-abi3-win_amd64.whl (270 kB)\n",
      "Collecting httptools>=0.5.0\n",
      "  Using cached httptools-0.5.0-cp310-cp310-win_amd64.whl (142 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (3.5.0)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (1.2.0)\n",
      "Collecting pyreadline3\n",
      "  Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Building wheels for collected packages: hnswlib\n",
      "  Building wheel for hnswlib (pyproject.toml): started\n",
      "  Building wheel for hnswlib (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp310-cp310-win_amd64.whl size=140765 sha256=e08f6bdbbb6945bc54ff228fec349e41829715ff754fa379b9b8f8bc833d7b24\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\36\\5e\\06\\bba7cbc79ef454a94746ba051381601575597e1b324b1221da\n",
      "Successfully built hnswlib\n",
      "Installing collected packages: tokenizers, pyreadline3, duckdb, websockets, pulsar-client, overrides, humanfriendly, httptools, hnswlib, clickhouse-connect, watchfiles, uvicorn, starlette, posthog, coloredlogs, onnxruntime, fastapi, chromadb\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.11.4\n",
      "    Uninstalling tokenizers-0.11.4:\n",
      "      Successfully uninstalled tokenizers-0.11.4\n",
      "Successfully installed chromadb-0.3.26 clickhouse-connect-0.6.2 coloredlogs-15.0.1 duckdb-0.8.1 fastapi-0.97.0 hnswlib-0.7.0 httptools-0.5.0 humanfriendly-10.0 onnxruntime-1.15.0 overrides-7.3.1 posthog-3.0.1 pulsar-client-3.2.0 pyreadline3-3.4.1 starlette-0.27.0 tokenizers-0.13.3 uvicorn-0.22.0 watchfiles-0.19.0 websockets-11.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39feb10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.indexes.vectorstore import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "279b4954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1163, which is longer than the specified 1000\n",
      "Created a chunk of size 1015, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "with open(\"./state_of_the_union.txt\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_text(state_of_the_union)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80470497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    }
   ],
   "source": [
    "docsearch = Chroma.from_texts(texts, embeddings, metadatas=[{\"source\": str(i)} for i in range(len(texts))]).as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4c6f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What did the president say about Justice Breyer\"\n",
    "docs = docsearch.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0babf771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7185df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The president did not mention Justice Breyer in this context.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
    "query = \"What did the president say about Justice Breyer\"\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eda27aa",
   "metadata": {},
   "source": [
    "### Stuff chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2bc6991",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10fa7329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': ' Joe Biden'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who is the vice president\"\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54869565",
   "metadata": {},
   "source": [
    "### Custom Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2ff3597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': ' Il vice presidente è Joe Biden.'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer in Italian:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\", prompt=PROMPT)\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce10270",
   "metadata": {},
   "source": [
    "### Map_reduce chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a522e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"map_reduce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc752d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': ' The president mentioned that the American people have felt the pain of recession.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What about recession in America\"\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baa316d",
   "metadata": {},
   "source": [
    "### Intermediate Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "564cd5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"map_reduce\", return_map_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9c383b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': [' None',\n",
       "  ' \"And they have done so in the midst of war and depression; at moments of great strife and great struggle.\"',\n",
       "  \" It is because of this spirit, this great decency and great strength that I have never been more hopeful about America's future than I am tonight. Despite our hardships, our union is strong. We do not give up. We do not quit. We do not allow fear or division to break our spirit. In this new decade, it's time the American people get a government that matches their decency, that embodies their strength.\",\n",
       "  ' \"We have felt the pain of recession\"'],\n",
       " 'output_text': ' The president mentioned that the American people have felt the pain of recession.'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c077f8b",
   "metadata": {},
   "source": [
    "### Custom Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e81c13d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': [' अमेरिका में मंडली के बारे में क्या?',\n",
       "  ' हमारे संविधान में कहा गया है कि कई बार राष्ट्रपति को संसद को हमारे समूह के बारे में जानकारी देनी चाहिए। 220 सालों से हमारे नेताओं ने इस कर्तव्य को पूरा किया है। वे सुख और शांत',\n",
       "  ' अमेरिका में अवसर के बारे में क्या? हम सभी ने बैंक बैलट को नफरत की थी। मैं इसे नफरत करता था। आप इसे नफरत करते थे। यह एक दांत की तरह की प्रतिक्रिया के समान था।',\n",
       "  ' अमेरिका में अर्थव्यवस्था में क्या हुआ? उसके लिए संबंधित पाठ, यदि कोई हो, हिंदी में: अमेरिका में अर्थव्यवस्था में क्या हुआ? उसके लिए उन कई लोगों को जो इस साल सभी देश म'],\n",
       " 'output_text': ' अमेरिका में अर्थव्यवस्था में क्या हुआ? अमेरिका में पिछले कुछ सालों से मंडली का अभाव हुआ है। यह अमेरिका के अर्थव्यवस्था को अस्थिर बनाने के लिए काफी प्रभावी रहा है। अम'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_prompt_template = \"\"\"Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
    "Return any relevant text translated into Hindi.\n",
    "{context}\n",
    "Question: {question}\n",
    "Relevant text, if any, in Hindi:\"\"\"\n",
    "QUESTION_PROMPT = PromptTemplate(\n",
    "    template=question_prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "combine_prompt_template = \"\"\"Given the following extracted parts of a long document and a question, create a final answer Hindi. \n",
    "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "\n",
    "QUESTION: {question}\n",
    "=========\n",
    "{summaries}\n",
    "=========\n",
    "Answer in Hindi:\"\"\"\n",
    "COMBINE_PROMPT = PromptTemplate(\n",
    "    template=combine_prompt_template, input_variables=[\"summaries\", \"question\"]\n",
    ")\n",
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"map_reduce\", return_map_steps=True, question_prompt=QUESTION_PROMPT, combine_prompt=COMBINE_PROMPT)\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57329a92",
   "metadata": {},
   "source": [
    "### Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3db44019",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"refine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8523138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': '\\n\\nAmericans face difficulty with civil rights violations, employment discrimination, hate crimes, unequal pay for women, a broken immigration system, a lack of economic opportunity for many communities, and the effects of the economic crisis on the banking system, as well as the political setbacks that have been experienced this year. Despite these difficulties, Americans remain resilient and determined, and continue to demonstrate their fundamental decency and optimism.'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the difficulty face by Americans's\"\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c114c6",
   "metadata": {},
   "source": [
    "### Intermediate steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4910643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"refine\", return_refine_steps=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e5d4fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': ['\\nAmericans face difficulty with civil rights violations, employment discrimination, hate crimes, unequal pay for women, and a broken immigration system.',\n",
       "  '\\n\\nAmericans face difficulty with civil rights violations, employment discrimination, hate crimes, unequal pay for women, a broken immigration system, and a lack of economic opportunity for many communities.',\n",
       "  '\\n\\nAmericans face difficulty with civil rights violations, employment discrimination, hate crimes, unequal pay for women, a broken immigration system, a lack of economic opportunity for many communities, and the effects of the economic crisis on the banking system.',\n",
       "  '\\n\\nAmericans face difficulty with civil rights violations, employment discrimination, hate crimes, unequal pay for women, a broken immigration system, a lack of economic opportunity for many communities, and the effects of the economic crisis on the banking system, as well as the political setbacks that have been experienced this year. Despite these difficulties, Americans remain resilient and determined, and continue to demonstrate their fundamental decency and optimism.'],\n",
       " 'output_text': '\\n\\nAmericans face difficulty with civil rights violations, employment discrimination, hate crimes, unequal pay for women, a broken immigration system, a lack of economic opportunity for many communities, and the effects of the economic crisis on the banking system, as well as the political setbacks that have been experienced this year. Despite these difficulties, Americans remain resilient and determined, and continue to demonstrate their fundamental decency and optimism.'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b48664",
   "metadata": {},
   "source": [
    "### Custom Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a93b7ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': ['\\nGli americani affrontano difficoltà come la discriminazione nei luoghi di lavoro, la mancanza di diritti civili, la mancanza di parità di retribuzione tra uomini e donne, e la mancanza di un sistema di immigrazione equo.',\n",
       "  '\\n\\nGli americani affrontano difficoltà come la discriminazione nei luoghi di lavoro, la mancanza di diritti civili, la mancanza di parità di retribuzione tra uomini e donne, la mancanza di un sistema di immigrazione equo e la disuguaglianza economica.',\n",
       "  '\\n\\nGli americani affrontano difficoltà come la discriminazione nei luoghi di lavoro, la mancanza di diritti civili, la mancanza di parità di retribuzione tra uomini e donne, la mancanza di un sistema di immigrazione equo, la disuguaglianza economica e la crisi economica.',\n",
       "  '\\n\\nGli americani affrontano difficoltà come la discriminazione nei luoghi di lavoro, la mancanza di diritti civili, la mancanza di parità di retribuzione tra uomini e donne, la mancanza di un sistema di immigrazione equo, la disuguaglianza economica, la crisi economica e le difficoltà politiche che la nostra amministrazione ha affrontato quest\\'anno. Nonostante tutte queste difficoltà, lo spirito di determinazione e ottimismo, la decenza fondamentale che è sempre stata al centro del popolo americano, vive ancora. Vive nei piccoli imprenditori che lottano per far crescere le loro aziende, nella donna che ha detto che anche se lei e i suoi vicini hanno sentito la sofferenza della recessione, \"Siamo forti. Siamo resilienti. Siamo americani\".'],\n",
       " 'output_text': '\\n\\nGli americani affrontano difficoltà come la discriminazione nei luoghi di lavoro, la mancanza di diritti civili, la mancanza di parità di retribuzione tra uomini e donne, la mancanza di un sistema di immigrazione equo, la disuguaglianza economica, la crisi economica e le difficoltà politiche che la nostra amministrazione ha affrontato quest\\'anno. Nonostante tutte queste difficoltà, lo spirito di determinazione e ottimismo, la decenza fondamentale che è sempre stata al centro del popolo americano, vive ancora. Vive nei piccoli imprenditori che lottano per far crescere le loro aziende, nella donna che ha detto che anche se lei e i suoi vicini hanno sentito la sofferenza della recessione, \"Siamo forti. Siamo resilienti. Siamo americani\".'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refine_prompt_template = (\n",
    "    \"The original question is as follows: {question}\\n\"\n",
    "    \"We have provided an existing answer: {existing_answer}\\n\"\n",
    "    \"We have the opportunity to refine the existing answer\"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Given the new context, refine the original answer to better \"\n",
    "    \"answer the question. \"\n",
    "    \"If the context isn't useful, return the original answer. Reply in Italian.\"\n",
    ")\n",
    "refine_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"existing_answer\", \"context_str\"],\n",
    "    template=refine_prompt_template,\n",
    ")\n",
    "\n",
    "\n",
    "initial_qa_template = (\n",
    "    \"Context information is below. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"answer the question: {question}\\nYour answer should be in Italian.\\n\"\n",
    ")\n",
    "initial_qa_prompt = PromptTemplate(\n",
    "    input_variables=[\"context_str\", \"question\"], template=initial_qa_template\n",
    ")\n",
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"refine\", return_refine_steps=True,\n",
    "                     question_prompt=initial_qa_prompt, refine_prompt=refine_prompt)\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f23e20",
   "metadata": {},
   "source": [
    "### Map Rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94504ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"map_rerank\", return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2419a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the difficulty face by Americans's\"\n",
    "results = chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "55b66708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Difficulty faced by Americans include civil rights violations, employment discrimination, unequal pay for women, and a broken immigration system.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"output_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d85bbd96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': ' Difficulty faced by Americans include civil rights violations, employment discrimination, unequal pay for women, and a broken immigration system.',\n",
       "  'score': '100'},\n",
       " {'answer': ' This document does not answer the question.', 'score': '0'},\n",
       " {'answer': ' The difficulty faced by Americans is the bank bailout, which was unpopular with both Democrats and Republicans.',\n",
       "  'score': '80'},\n",
       " {'answer': ' The difficulty faced by Americans include political setbacks, economic recession, and other struggles.',\n",
       "  'score': '80'}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"intermediate_steps\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc97ee1",
   "metadata": {},
   "source": [
    "### Custom Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "68d6e75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': [{'answer': ' उम्मीदवार कौन है?', 'score': '0'},\n",
       "  {'answer': ' उम्मीदवार बाइडेन है।', 'score': '100'},\n",
       "  {'answer': ' उम्मीद करता हूँ कि आपको यह जानना आवश्यक नहीं है।',\n",
       "   'score': '0'},\n",
       "  {'answer': ' उम्मीदवार कौन है?', 'score': '0'}],\n",
       " 'output_text': ' उम्मीदवार बाइडेन है।'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import RegexParser\n",
    "\n",
    "output_parser = RegexParser(\n",
    "    regex=r\"(.*?)\\nScore: (.*)\",\n",
    "    output_keys=[\"answer\", \"score\"],\n",
    ")\n",
    "\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
    "\n",
    "Question: [question here]\n",
    "Helpful Answer In Hindi: [answer here]\n",
    "Score: [score between 0 and 100]\n",
    "\n",
    "Begin!\n",
    "\n",
    "Context:\n",
    "---------\n",
    "{context}\n",
    "---------\n",
    "Question: {question}\n",
    "Helpful Answer In Hindi:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    output_parser=output_parser,\n",
    ")\n",
    "\n",
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"map_rerank\", return_intermediate_steps=True, prompt=PROMPT)\n",
    "query = \"Who is the vice president\"\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d296904f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d8694c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e9f0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5e81fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6342c750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
